{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78e87c50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import scipy.io as sio\n",
    "import datetime as dt\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.transform import rescale as skrescale\n",
    "from scipy import signal as ssignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a94b06e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#vstring = int(sys.argv[1])\n",
    "rseed = int(330)\n",
    "#humidvar = sys.argv[3]\n",
    "import random\n",
    "random.seed(rseed)\n",
    "np.random.seed(rseed)\n",
    "torch.manual_seed(rseed)\n",
    "torch.cuda.manual_seed(rseed)\n",
    "torch.cuda.manual_seed_all(rseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a0553de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt_model = 'R18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7890a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e87556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SCL(nn.Module):\n",
    "    \"\"\"\n",
    "    We opt for simplicity and adopt the commonly used ResNet (He et al., 2016) to obtain hi = f(x ̃i) = ResNet(x ̃i) where hi ∈ Rd is the output after the average pooling layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train, encoder, projection_dim, n_features):\n",
    "        super(SCL, self).__init__()\n",
    "        self.train = train\n",
    "        self.encoder = encoder\n",
    "        self.n_features = n_features\n",
    "\n",
    "        # increse input channel to 6\n",
    "        layer = self.encoder.conv1\n",
    "        new_nc = 6\n",
    "        new_layer = nn.Conv2d(in_channels=new_nc,\n",
    "                              out_channels=layer.out_channels,\n",
    "                              kernel_size=layer.kernel_size,\n",
    "                              stride=layer.stride,\n",
    "                              padding=layer.padding,\n",
    "                              bias=layer.bias)\n",
    "        # Extending the weights by copying from the old 3 to the new 3 channels\n",
    "        new_layer.weight.data[:, 0:3, :, :] = layer.weight.clone()\n",
    "        new_layer.weight.data[:, 3:6, :, :] = layer.weight.clone()\n",
    "        new_layer.weight = nn.Parameter(new_layer.weight)\n",
    "        self.encoder.conv1 = new_layer\n",
    "\n",
    "        # Replace the fc layer with an Identity function\n",
    "        self.encoder.fc = Identity()\n",
    "        # We use a MLP with one hidden layer to obtain z_i = g(h_i) = W(2)σ(W(1)h_i) where σ is a ReLU non-linearity.\n",
    "        # xc: This is the part that needs to be trained\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(self.n_features, self.n_features, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.n_features, projection_dim, bias=False),\n",
    "        )\n",
    "        # These are the parameters obtained from simCLR repo. I have also patched it to include 6 channels at the conv1\n",
    "        param_file = rootdir + 'model_lib/SCL_param.encoder.%s.6_channel.init.tar' % opt_model\n",
    "        self.encoder.load_state_dict(torch.load(param_file, map_location='cpu'))\n",
    "\n",
    "\n",
    "        # freeze the encoder so it is not re-trained\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, x_i):\n",
    "        # z_i = self.encoder(x_i.type(torch.FloatTensor).cuda()).type(torch.FloatTensor).cuda()\n",
    "        z_i = self.encoder(x_i.type(torch.FloatTensor)).type(torch.FloatTensor)\n",
    "\n",
    "        del x_i\n",
    "        return z_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2286bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collect_norm_data_by_var(my_var):\n",
    "\n",
    "#     sfile_max = datadir + 'agg_40year/minmax/pt.max.%s.nc' % my_var\n",
    "#     sfile_min = datadir + 'agg_40year/minmax/pt.min.%s.nc' % my_var\n",
    "\n",
    "#     with xr.open_dataset(sfile_max) as inds:\n",
    "#         ds_Vmax = inds[my_var].values\n",
    "\n",
    "#     with xr.open_dataset(sfile_min) as inds:\n",
    "#         ds_Vmin = inds[my_var].values\n",
    "        \n",
    "#     print(ds_Vmax, ds_Vmin)\n",
    "\n",
    "#     my_vmax = np.maximum(ds_Vmax, -1*ds_Vmin)\n",
    "#     Vmax, Vmin = my_vmax, -1*my_vmax\n",
    "    \n",
    "#     infile = datadir + 'ERA5.SCL.850mb_anomaly.%s.1981-2020.daymean.nc' % (my_var)\n",
    "#     print('loading data from %s ...' % infile)\n",
    "#     with xr.open_dataset(infile) as inds:\n",
    "#         outdata = (inds[my_var].values[:,0,:,:]-Vmin)/(Vmax-Vmin)\n",
    "\n",
    "#     return outdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e58edccb-abec-49c2-a559-1e54ac75bb6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collect_norm_data_by_var(my_var, vname):\n",
    "    \n",
    "    fname = f'{datadir}/{my_var}.2001-2020.anomaly.nc'\n",
    "    with xr.open_dataset(fname) as ds:\n",
    "        da = ds[vname]\n",
    "        da_max = da.max(['time','latitude','longitude']).data\n",
    "        da_min = da.max(['time','latitude','longitude']).data\n",
    "        \n",
    "        my_vmax = np.maximum(da_max, -1*da_min)\n",
    "        vmax, vmin = my_vmax, -1*my_vmax\n",
    "        print(f'{my_var}: {vmin}, {vmax}')\n",
    "        \n",
    "        out = (da - vmin) / (vmax - vmin)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "695ffd19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean5kernel = np.ones((5,5))/25\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    '''\n",
    "    Since we need to mannually normalize the data, let's create datasets elsewhere, and just aggreagate them here.\n",
    "    Requires: T_full, H_full, W_full, U_full, V_full, Z_full\n",
    "    '''\n",
    "\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.sample_data = root_dir + 't500.2001-2020.anomaly.nc'\n",
    "\n",
    "    def __len__(self):\n",
    "        with xr.open_dataset(self.sample_data) as inds:\n",
    "            nt = inds['T'].shape[0]\n",
    "        return int(nt)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # find a corresponding idx_pair, outside the 360-length window of idx\n",
    "        # idx_pair = xxxx\n",
    "\n",
    "\n",
    "        sample_raw = np.zeros((6,92,112))\n",
    "\n",
    "        for i,fullds in zip(np.arange(6), [t500_full, t850_full, z500_full, z850_full, z500_full, z850_full]):\n",
    "            \n",
    "            # construct input for idx\n",
    "            # rescaling\n",
    "            data_step1 = skrescale(fullds[idx], (2.5, 2.5), anti_aliasing=True)\n",
    "            # mean using 5x5\n",
    "            data_step2 = ssignal.convolve2d(data_step1, mean5kernel, boundary='symm', mode='same')\n",
    "            sample_raw[i] = data_step2\n",
    "\n",
    "\n",
    "            # construct input for idx_pair\n",
    "            # rescaling\n",
    "\n",
    "            # mean using 5x5\n",
    "\n",
    "        return sample_raw, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4a9ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCLloss(my_x, my_y, my_temperature=0.5):\n",
    "    '''\n",
    "    my_x and my_y has a one-to-one pair. So there are in total N*N pairs. In these N*N, the diagonal pairs are positive,\n",
    "     and the rest are negative. So we want to maximum diagonal while suppressing the rest.\n",
    "    '''\n",
    "    ns = my_x.shape[0]\n",
    "    # use broadcasting to achieve pairwise cos. Note my_y.t() operation and dimension handling\n",
    "    cos_matrix = torch.nn.functional.cosine_similarity(my_x[:,:,None], my_y.t()[None,:,:])/my_temperature\n",
    "    similarity_matrix = torch.exp(cos_matrix)\n",
    "\n",
    "\n",
    "    loss = torch.tensor([0.0], requires_grad=True)\n",
    "    for i in np.arange(ns):\n",
    "        loss = loss -1*torch.log(similarity_matrix[i,i]/(torch.sum(similarity_matrix[i,:])-similarity_matrix[i,i]))\n",
    "        loss = loss -1*torch.log(similarity_matrix[i,i]/(torch.sum(similarity_matrix[:,i])-similarity_matrix[i,i]))\n",
    "\n",
    "    loss = loss/(2*ns)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd2f3fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rootdir = '/global/cfs/projectdirs/m1657/liuy351/TallTower/'\n",
    "\n",
    "datadir = '/global/cfs/projectdirs/m1657/liuy351/TallTower/ERA5_reduced/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "357b07f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0. major parameters\n",
    "if opt_model=='R18':\n",
    "    batch_size = 128\n",
    "elif opt_model=='R15':\n",
    "    batch_size = 64\n",
    "    \n",
    "# 1. construct functions\n",
    "if opt_model=='R18':\n",
    "    encoder = torchvision.models.resnet18(weights=None)\n",
    "elif opt_model=='R50':\n",
    "    encoder = torchvision.models.resnet50(weights=None)\n",
    "\n",
    "n_features = encoder.fc.in_features  # get dimensions of fc layer\n",
    "\n",
    "# 2. construct two models, one with random parameters, one with pre-trained parameters\n",
    "projection_dim = 256\n",
    "SCL = SCL(True, encoder, projection_dim, n_features)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "SCL = SCL.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b56f49a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t500: -16.976272583007812, 16.976272583007812\n",
      "t850: -20.182464599609375, 20.182464599609375\n",
      "z500: -3421.85546875, 3421.85546875\n",
      "z850: -2313.826171875, 2313.826171875\n",
      "(175320, 37, 45)\n"
     ]
    }
   ],
   "source": [
    "# 3. load data\n",
    "\n",
    "t500_full = collect_norm_data_by_var('t500', 'T')\n",
    "t850_full = collect_norm_data_by_var('t850', 'T')\n",
    "z500_full = collect_norm_data_by_var('z500', 'Z')\n",
    "z850_full = collect_norm_data_by_var('z850', 'Z')\n",
    "\n",
    "print(t500_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "449f8dd4-e3bb-4b07-a13d-1a6d4a08b0aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.42668014764785767\n"
     ]
    }
   ],
   "source": [
    "print(z850_full.min().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2acb773",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(root_dir=datadir)\n",
    "\n",
    "# turn off shuffle, so data is processed in the time order\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f69af58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1da0b748",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-20 14:19:03.436392\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (92,112) into shape (102,202)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m eindex \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(dt\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     testout = SCL(data[0].to(device))\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#     outdata[sindex:eindex, :] = testout.detach().cpu().numpy()\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     outindex[sindex:eindex] = data[1]\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[43], line 35\u001b[0m, in \u001b[0;36mTrainDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# mean using 5x5\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     data_step2 \u001b[38;5;241m=\u001b[39m ssignal\u001b[38;5;241m.\u001b[39mconvolve2d(data_step1, mean5kernel, boundary\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymm\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m     \u001b[43msample_raw\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m data_step2\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# construct input for idx_pair\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# rescaling\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# mean using 5x5\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sample_raw, idx\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (92,112) into shape (102,202)"
     ]
    }
   ],
   "source": [
    "outdata = np.zeros((t500_full.shape[0], n_features))\n",
    "outindex = np.zeros(t500_full.shape[0])\n",
    "\n",
    "sindex = -1*batch_size\n",
    "eindex = 0\n",
    "\n",
    "print(dt.datetime.now())\n",
    "for step, data in enumerate(train_dataloader):\n",
    "    print(data)\n",
    "\n",
    "#     testout = SCL(data[0].to(device))\n",
    "\n",
    "\n",
    "#     sindex = eindex\n",
    "#     eindex += testout.shape[0]\n",
    "\n",
    "#     outdata[sindex:eindex, :] = testout.detach().cpu().numpy()\n",
    "#     outindex[sindex:eindex] = data[1]\n",
    "\n",
    "    print(sindex, eindex)\n",
    "\n",
    "print(dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7cc2155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to /global/cfs/projectdirs/m1657/liuy351/TallTower/From_XD/ResNet_output/RH_input/R18_output.anomaly.daymean.1981-2020.ERA5.mat ...\n"
     ]
    }
   ],
   "source": [
    "outfile = rootdir + 'ResNet_output/RH_input/%s_output.anomaly.daymean.1981-2020.ERA5.mat' % opt_model\n",
    "print('writing to %s ...' % outfile)\n",
    "description = 'Just the simCLR encoder output. So in 512 dimension. Use %s model' % opt_model\n",
    "script = '/global/cfs/projectdirs/m1657/liuy351/TallTower/From_XD/step02.ResNet_encoder_production_run.ipynb'\n",
    "sio.savemat(outfile, {'ResNetoutput':outdata, 'tindex':outindex, 'description':description, 'script':script})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c3a725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myCompute",
   "language": "python",
   "name": "compute"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
