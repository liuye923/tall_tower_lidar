{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nj/3gr32m7s4454ds10_r619sqw0000gn/T/ipykernel_56909/3973344320.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hidden_states = torch.tensor(hidden_states, dtype=torch.float32)\n",
      "Epoch 1/10: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s]\n",
      "2024-06-28 17:01:08,541 - INFO - Epoch 1/10, Loss: 2.3007333278656006\n",
      "Epoch 2/10: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s]\n",
      "2024-06-28 17:01:08,675 - INFO - Epoch 2/10, Loss: 2.1291894912719727\n",
      "Epoch 3/10: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s]\n",
      "2024-06-28 17:01:08,803 - INFO - Epoch 3/10, Loss: 1.8556734323501587\n",
      "Epoch 4/10: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s]\n",
      "2024-06-28 17:01:08,929 - INFO - Epoch 4/10, Loss: 1.3017315864562988\n",
      "Epoch 5/10: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s]\n",
      "2024-06-28 17:01:09,059 - INFO - Epoch 5/10, Loss: 0.4733865261077881\n",
      "Epoch 6/10: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s]\n",
      "2024-06-28 17:01:09,190 - INFO - Epoch 6/10, Loss: 0.08597078174352646\n",
      "Epoch 7/10: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s]\n",
      "2024-06-28 17:01:09,318 - INFO - Epoch 7/10, Loss: 0.022380398586392403\n",
      "Epoch 8/10: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s]\n",
      "2024-06-28 17:01:09,443 - INFO - Epoch 8/10, Loss: 0.008363697677850723\n",
      "Epoch 9/10: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s]\n",
      "2024-06-28 17:01:09,578 - INFO - Epoch 9/10, Loss: 0.0037512665148824453\n",
      "Epoch 10/10: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
      "2024-06-28 17:01:09,737 - INFO - Epoch 10/10, Loss: 0.001933254417963326\n",
      "2024-06-28 17:01:09,744 - INFO - LSTM classifier model saved to lstm_classifier_model.pth\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define the LSTM-based classifier model\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]  # Take the output from the last time step\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Load hidden states\n",
    "hidden_states = torch.load('hidden_states.ViT.pt')\n",
    "\n",
    "# Convert hidden states to torch tensor\n",
    "hidden_states = torch.tensor(hidden_states, dtype=torch.float32)\n",
    "\n",
    "# Example target labels for training (replace with actual labels)\n",
    "# Assuming there are 10 classes and hidden states shape is (num_samples, seq_length, feature_dim)\n",
    "num_samples, seq_length, feature_dim = hidden_states.shape\n",
    "num_classes = 10  # Adjust based on your classification task\n",
    "targets = torch.randint(0, num_classes, (num_samples,))\n",
    "\n",
    "# Define the LSTM-based classifier\n",
    "hidden_dim = 256\n",
    "num_layers = 2\n",
    "classifier = LSTMClassifier(input_dim=feature_dim, hidden_dim=hidden_dim, num_layers=num_layers, num_classes=num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "# Training the classifier\n",
    "epochs = 10\n",
    "classifier.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for i in tqdm(range(num_samples), desc=f\"Epoch {epoch + 1}/{epochs}\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Select the hidden states for the current sample\n",
    "        input_data = hidden_states[i].unsqueeze(0)  # Add batch dimension\n",
    "        target = targets[i].unsqueeze(0)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = classifier(input_data)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, target)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    logging.info(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / num_samples}\")\n",
    "\n",
    "# Save the trained classifier model\n",
    "torch.save(classifier.state_dict(), 'lstm_classifier_model.pth')\n",
    "logging.info(\"LSTM classifier model saved to lstm_classifier_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lstm.weight_ih_l0',\n",
       "              tensor([[ 0.0451,  0.0646, -0.0487,  ...,  0.0495,  0.0454,  0.0267],\n",
       "                      [-0.0270, -0.0241,  0.0064,  ...,  0.0238, -0.0332, -0.0189],\n",
       "                      [-0.0216,  0.0276,  0.0637,  ..., -0.0586,  0.0441, -0.0132],\n",
       "                      ...,\n",
       "                      [-0.0433,  0.0146,  0.0510,  ..., -0.0431, -0.0415,  0.0565],\n",
       "                      [ 0.0479,  0.0504,  0.0657,  ...,  0.0137, -0.0403, -0.0152],\n",
       "                      [ 0.0342, -0.0361, -0.0467,  ...,  0.0110, -0.0389, -0.0284]])),\n",
       "             ('lstm.weight_hh_l0',\n",
       "              tensor([[ 0.0446, -0.0529,  0.0470,  ...,  0.0509, -0.0126,  0.0320],\n",
       "                      [ 0.0141,  0.0589, -0.0005,  ...,  0.0606,  0.0364, -0.0175],\n",
       "                      [ 0.0671,  0.0305,  0.0130,  ..., -0.0040,  0.0197, -0.0067],\n",
       "                      ...,\n",
       "                      [ 0.0237, -0.0113, -0.0241,  ...,  0.0621, -0.0139, -0.0629],\n",
       "                      [-0.0541,  0.0266, -0.0529,  ...,  0.0415, -0.0542,  0.0268],\n",
       "                      [-0.0389, -0.0435,  0.0261,  ...,  0.0583, -0.0253,  0.0382]])),\n",
       "             ('lstm.bias_ih_l0',\n",
       "              tensor([-0.0533,  0.0452,  0.0117,  ..., -0.0411,  0.0705,  0.0687])),\n",
       "             ('lstm.bias_hh_l0',\n",
       "              tensor([-0.0161,  0.0011,  0.0622,  ...,  0.0588, -0.0468,  0.0411])),\n",
       "             ('lstm.weight_ih_l1',\n",
       "              tensor([[ 0.0029,  0.0140,  0.0273,  ..., -0.0209, -0.0671, -0.0517],\n",
       "                      [ 0.0647, -0.0484,  0.0525,  ...,  0.0368,  0.0537,  0.0449],\n",
       "                      [-0.0267,  0.0378,  0.0132,  ...,  0.0061,  0.0076,  0.0256],\n",
       "                      ...,\n",
       "                      [ 0.0532,  0.0678,  0.0448,  ..., -0.0084,  0.0048,  0.0477],\n",
       "                      [ 0.0150,  0.0003,  0.0394,  ..., -0.0273,  0.0350,  0.0379],\n",
       "                      [ 0.0614, -0.0524, -0.0281,  ..., -0.0041, -0.0620, -0.0059]])),\n",
       "             ('lstm.weight_hh_l1',\n",
       "              tensor([[-0.0481, -0.0099,  0.0242,  ..., -0.0609, -0.0267, -0.0014],\n",
       "                      [ 0.0466, -0.0261,  0.0043,  ...,  0.0547, -0.0435,  0.0214],\n",
       "                      [ 0.0146,  0.0646, -0.0390,  ...,  0.0449, -0.0220,  0.0067],\n",
       "                      ...,\n",
       "                      [ 0.0372, -0.0395,  0.0071,  ..., -0.0147,  0.0368,  0.0380],\n",
       "                      [ 0.0663, -0.0546, -0.0659,  ...,  0.0429, -0.0463,  0.0299],\n",
       "                      [ 0.0532,  0.0076, -0.0044,  ...,  0.0067,  0.0376,  0.0050]])),\n",
       "             ('lstm.bias_ih_l1',\n",
       "              tensor([ 0.0451,  0.0166,  0.0558,  ..., -0.0599, -0.0329,  0.0445])),\n",
       "             ('lstm.bias_hh_l1',\n",
       "              tensor([ 0.0353,  0.0454,  0.0377,  ...,  0.0625,  0.0520, -0.0306])),\n",
       "             ('fc.weight',\n",
       "              tensor([[-0.0055, -0.0203,  0.0187,  ..., -0.0137, -0.0687, -0.0334],\n",
       "                      [-0.0366, -0.0433, -0.0113,  ...,  0.0569, -0.0538,  0.0386],\n",
       "                      [-0.0356, -0.0272,  0.0516,  ...,  0.0531, -0.0369,  0.0164],\n",
       "                      ...,\n",
       "                      [ 0.0056,  0.0461, -0.0185,  ...,  0.0429, -0.0322,  0.0001],\n",
       "                      [ 0.0450, -0.0104,  0.0321,  ..., -0.0578,  0.0680,  0.0308],\n",
       "                      [-0.0591, -0.0272,  0.0554,  ...,  0.0541, -0.0180, -0.0433]])),\n",
       "             ('fc.bias',\n",
       "              tensor([ 0.0147, -0.0642,  0.0416, -0.0642,  0.0402, -0.0579,  0.0255, -0.0440,\n",
       "                       0.0159, -0.0343]))])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.6061102151870728\n",
      "Epoch 2/10, Loss: 1.5997072458267212\n",
      "Epoch 3/10, Loss: 1.5961003303527832\n",
      "Epoch 4/10, Loss: 1.5945404767990112\n",
      "Epoch 5/10, Loss: 1.5939780473709106\n",
      "Epoch 6/10, Loss: 1.5937540531158447\n",
      "Epoch 7/10, Loss: 1.5935587882995605\n",
      "Epoch 8/10, Loss: 1.5932397842407227\n",
      "Epoch 9/10, Loss: 1.5927554368972778\n",
      "Epoch 10/10, Loss: 1.5921286344528198\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load precomputed hidden states\n",
    "hidden_states = torch.load('hidden_states.Vit.pt')  # Shape: (batch_size, seq_length, hidden_dim * 2)\n",
    "\n",
    "# Define a classifier model\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, hidden_dim=512, num_classes=10):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)  # Multiply by 2 for bidirectional LSTM\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Train classifier\n",
    "num_classes = 5  # Example number of classes, can be tuned\n",
    "classifier = LSTMClassifier(hidden_dim=512, num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "# Example target labels for training\n",
    "target = torch.randint(0, num_classes, (hidden_states.size(0), hidden_states.size(1)))\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = classifier(hidden_states)  # Shape: (batch_size, seq_length, num_classes)\n",
    "    loss = criterion(output.view(-1, num_classes), target.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc.weight',\n",
       "              tensor([[ 0.0330, -0.0013,  0.0235,  ...,  0.0345, -0.0162,  0.0071],\n",
       "                      [-0.0045, -0.0024,  0.0265,  ..., -0.0199, -0.0076, -0.0215],\n",
       "                      [ 0.0223, -0.0006, -0.0237,  ..., -0.0222,  0.0321, -0.0128],\n",
       "                      [-0.0111,  0.0236,  0.0054,  ..., -0.0127,  0.0330,  0.0300],\n",
       "                      [-0.0327,  0.0120, -0.0040,  ..., -0.0047, -0.0002,  0.0152]])),\n",
       "             ('fc.bias',\n",
       "              tensor([ 0.0233,  0.0280, -0.0015,  0.0042,  0.0262]))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nj/3gr32m7s4454ds10_r619sqw0000gn/T/ipykernel_56909/1343907352.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hidden_states = torch.tensor(hidden_states, dtype=torch.float32)\n",
      "Epoch 1/10: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n",
      "2024-06-28 17:01:29,652 - INFO - Epoch 1/10, Loss: 2.280545473098755\n",
      "Epoch 2/10: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s]\n",
      "2024-06-28 17:01:29,771 - INFO - Epoch 2/10, Loss: 2.1285898685455322\n",
      "Epoch 3/10: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n",
      "2024-06-28 17:01:29,908 - INFO - Epoch 3/10, Loss: 1.8932427167892456\n",
      "Epoch 4/10: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s]\n",
      "2024-06-28 17:01:30,029 - INFO - Epoch 4/10, Loss: 1.4138613939285278\n",
      "Epoch 5/10: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s]\n",
      "2024-06-28 17:01:30,148 - INFO - Epoch 5/10, Loss: 0.6126784086227417\n",
      "Epoch 6/10: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s]\n",
      "2024-06-28 17:01:30,266 - INFO - Epoch 6/10, Loss: 0.1227807104587555\n",
      "Epoch 7/10: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s]\n",
      "2024-06-28 17:01:30,383 - INFO - Epoch 7/10, Loss: 0.029265454038977623\n",
      "Epoch 8/10: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s]\n",
      "2024-06-28 17:01:30,500 - INFO - Epoch 8/10, Loss: 0.009947370737791061\n",
      "Epoch 9/10: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s]\n",
      "2024-06-28 17:01:30,622 - INFO - Epoch 9/10, Loss: 0.004113427828997374\n",
      "Epoch 10/10: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s]\n",
      "2024-06-28 17:01:30,737 - INFO - Epoch 10/10, Loss: 0.00197001826018095\n",
      "2024-06-28 17:01:30,745 - INFO - LSTM classifier model saved to lstm_classifier_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits:\n",
      " tensor([[-1.9154, -0.3192, -1.6114,  7.6093, -1.7138, -1.6429, -1.8956, -1.6316,\n",
      "         -2.1856, -1.3644]])\n",
      "Probabilities:\n",
      " tensor([[7.2948e-05, 3.5994e-04, 9.8869e-05, 9.9893e-01, 8.9239e-05, 9.5799e-05,\n",
      "         7.4403e-05, 9.6889e-05, 5.5675e-05, 1.2656e-04]])\n",
      "Predicted Class:\n",
      " tensor([3])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define the LSTM-based classifier model\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]  # Take the output from the last time step\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Load hidden states\n",
    "hidden_states = torch.load('hidden_states.ViT.pt')\n",
    "\n",
    "# Convert hidden states to torch tensor\n",
    "hidden_states = torch.tensor(hidden_states, dtype=torch.float32)\n",
    "\n",
    "# Example target labels for training (replace with actual labels)\n",
    "# Assuming there are 10 classes and hidden states shape is (num_samples, seq_length, feature_dim)\n",
    "num_samples, seq_length, feature_dim = hidden_states.shape\n",
    "num_classes = 10  # Adjust based on your classification task\n",
    "targets = torch.randint(0, num_classes, (num_samples,))\n",
    "\n",
    "# Define the LSTM-based classifier\n",
    "hidden_dim = 256\n",
    "num_layers = 2\n",
    "classifier = LSTMClassifier(input_dim=feature_dim, hidden_dim=hidden_dim, num_layers=num_layers, num_classes=num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "# Training the classifier\n",
    "epochs = 10\n",
    "classifier.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for i in tqdm(range(num_samples), desc=f\"Epoch {epoch + 1}/{epochs}\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Select the hidden states for the current sample\n",
    "        input_data = hidden_states[i].unsqueeze(0)  # Add batch dimension\n",
    "        target = targets[i].unsqueeze(0)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = classifier(input_data)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, target)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    logging.info(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / num_samples}\")\n",
    "\n",
    "# Save the trained classifier model\n",
    "torch.save(classifier.state_dict(), 'lstm_classifier_model.pth')\n",
    "logging.info(\"LSTM classifier model saved to lstm_classifier_model.pth\")\n",
    "\n",
    "# Evaluating the model (Example)\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    sample_data = hidden_states[0].unsqueeze(0)  # Select the first sample\n",
    "    logits = classifier(sample_data)\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "    print(\"Logits:\\n\", logits)\n",
    "    print(\"Probabilities:\\n\", probabilities)\n",
    "    print(\"Predicted Class:\\n\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile 'hidden_states.ViT.pt' with keys: hidden_states.ViT/data.pkl, hidden_states.ViT/byteorder, hidden_states.ViT/data/0, hidden_states.ViT/version, hidden_states.ViT/.data/serialization_id"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
