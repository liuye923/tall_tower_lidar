{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 12:04:18,328 - DEBUG - t500: -10.821197509765625, 10.821197509765625\n",
      "2024-06-29 12:04:18,477 - DEBUG - t850: -19.809478759765625, 19.809478759765625\n",
      "2024-06-29 12:04:18,563 - DEBUG - z500: -2312.375, 2312.375\n",
      "2024-06-29 12:04:18,640 - DEBUG - z850: -1227.3349609375, 1227.3349609375\n",
      "2024-06-29 12:04:18,790 - DEBUG - 2t: -21.785369873046875, 21.785369873046875\n",
      "2024-06-29 12:04:18,898 - DEBUG - sp: -1471.0546875, 1471.0546875\n",
      "2024-06-29 12:04:18,994 - DEBUG - Data shape after stacking and normalization: (2917, 6, 37, 45)\n",
      "2024-06-29 12:04:19,182 - INFO - Starting feature extraction for 1 batches\n",
      "Processing Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2917, 6, 37, 45])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 1/1 [00:04<00:00,  4.48s/it]\n",
      "2024-06-29 12:04:23,673 - INFO - Hidden states saved to hidden_states.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from vit_pytorch import ViT\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import xarray as xr\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "datadir = '../ERA5_reduced/'\n",
    "\n",
    "class ViTFeatureExtractor(nn.Module):\n",
    "    def __init__(self, image_size=(40, 45), patch_size=5, dim=512, depth=6, heads=8, mlp_dim=2048, channels=6):\n",
    "        super(ViTFeatureExtractor, self).__init__()\n",
    "        self.vit = ViT(\n",
    "            image_size=image_size,\n",
    "            patch_size=patch_size,\n",
    "            num_classes=dim,  # Output dimension of the ViT\n",
    "            dim=dim,\n",
    "            depth=depth,\n",
    "            heads=heads,\n",
    "            mlp_dim=mlp_dim,\n",
    "            channels=channels\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.vit(x)\n",
    "\n",
    "class ViT_BiLSTM_FeatureExtractor(nn.Module):\n",
    "    def __init__(self, image_size=(40, 45), patch_size=5, hidden_dim=512, num_layers=2):\n",
    "        super(ViT_BiLSTM_FeatureExtractor, self).__init__()\n",
    "        self.feature_extractor = ViTFeatureExtractor(image_size=image_size, patch_size=patch_size)\n",
    "        \n",
    "        # Bidirectional LSTM to model temporal dependencies\n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=512,  # This should match the output dimension of ViT\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, num_channels, height, width = x.size()\n",
    "        \n",
    "        # Reshape to (batch_size * seq_length, num_channels, height, width)\n",
    "        x = x.view(batch_size * seq_length, num_channels, height, width)\n",
    "        \n",
    "        # Feature extraction using ViT\n",
    "        features = self.feature_extractor(x)\n",
    "        \n",
    "        # Reshape to (batch_size, seq_length, feature_dim)\n",
    "        features = features.view(batch_size, seq_length, -1)\n",
    "        \n",
    "        # BiLSTM for temporal dependencies\n",
    "        bilstm_out, _ = self.bilstm(features)\n",
    "        \n",
    "        return bilstm_out\n",
    "\n",
    "def load_and_norm_single_variable_netcdf_data(my_var, vname, time=None):\n",
    "    fname = f'{datadir}/{my_var}.2001-2020.anomaly.nc'\n",
    "    \n",
    "    with xr.open_dataset(fname) as ds:\n",
    "        da = ds[vname]\n",
    "        if time is not None:\n",
    "            da = da.sel(time=slice(*time))\n",
    "        da_max = da.max(['time','latitude','longitude']).data\n",
    "        da_min = da.max(['time','latitude','longitude']).data\n",
    "        \n",
    "        my_vmax = np.maximum(da_max, -1*da_min)\n",
    "        vmax, vmin = my_vmax, -1*my_vmax\n",
    "        logging.debug(f'{my_var}: {vmin}, {vmax}')\n",
    "   \n",
    "        out = (da - vmin) / (vmax - vmin)\n",
    "        \n",
    "    return out\n",
    "\n",
    "def load_and_norm_netcdf_data(time=None):\n",
    "    t500_full = load_and_norm_single_variable_netcdf_data('t500', 'T', time=time)\n",
    "    t850_full = load_and_norm_single_variable_netcdf_data('t850', 'T', time=time)\n",
    "    z500_full = load_and_norm_single_variable_netcdf_data('z500', 'Z', time=time)\n",
    "    z850_full = load_and_norm_single_variable_netcdf_data('z850', 'Z', time=time)\n",
    "    t2_full   = load_and_norm_single_variable_netcdf_data('2t', 'VAR_2T', time=time)\n",
    "    sp_full   = load_and_norm_single_variable_netcdf_data('sp', 'SP', time=time)\n",
    "\n",
    "    data_list = [t500_full, t850_full, z500_full, z850_full, t2_full, sp_full]\n",
    "\n",
    "    time = data_list[0].time\n",
    "    for v in data_list:\n",
    "        time = np.intersect1d(time, v.time)\n",
    "\n",
    "    for v in data_list:\n",
    "        v = v.sel(time=time)\n",
    "    \n",
    "    normalized_data = np.stack(data_list, axis=1)\n",
    "\n",
    "    logging.debug(f\"Data shape after stacking and normalization: {normalized_data.shape}\")\n",
    "\n",
    "    return normalized_data\n",
    "\n",
    "# Ensure the input image size is compatible with the patch size\n",
    "def pad_image_to_fit_patch_size(data, patch_size):\n",
    "    _, _, height, width = data.shape\n",
    "    pad_height = (patch_size - height % patch_size) % patch_size\n",
    "    pad_width = (patch_size - width % patch_size) % patch_size\n",
    "    padded_data = np.pad(data, ((0, 0), (0, 0), (0, pad_height), (0, pad_width)), mode='constant', constant_values=0)\n",
    "    return padded_data\n",
    "\n",
    "def remove_diurnal_cycle(data, hours_per_day=24):\n",
    "    \"\"\"\n",
    "    Remove diurnal cycle by subtracting the hourly mean.\n",
    "    Args:\n",
    "        data (numpy array): The input data with shape (time, features).\n",
    "        hours_per_day (int): Number of hours in a day.\n",
    "    Returns:\n",
    "        numpy array: The data with diurnal cycle removed.\n",
    "    \"\"\"\n",
    "    num_days = data.shape[0] // hours_per_day\n",
    "    diurnal_means = np.zeros((hours_per_day, data.shape[1]))\n",
    "    \n",
    "    for hour in range(hours_per_day):\n",
    "        diurnal_means[hour] = np.mean(data[hour::hours_per_day], axis=0)\n",
    "    \n",
    "    data_no_diurnal = data.copy()\n",
    "    for hour in range(hours_per_day):\n",
    "        data_no_diurnal[hour::hours_per_day] -= diurnal_means[hour]\n",
    "    \n",
    "    return data_no_diurnal\n",
    "\n",
    "# Example usage to extract and store hidden states\n",
    "model = ViT_BiLSTM_FeatureExtractor(image_size=(37, 45), patch_size=(37, 45))\n",
    "\n",
    "# Load NetCDF data\n",
    "netcdf_file_path = 'path_to_your_netcdf_file.nc'\n",
    "input_data = load_and_norm_netcdf_data(time=('2016-06-01 00:00', '2016-09-30 12:00'))\n",
    "\n",
    "# Remove diurnal cycle\n",
    "input_data = remove_diurnal_cycle(input_data.reshape(-1, input_data.shape[-1])).reshape(input_data.shape)\n",
    "\n",
    "\n",
    "# # Pad image size to be compatible with patch size (e.g., 5x5)\n",
    "# input_data = pad_image_to_fit_patch_size(input_data, patch_size=5)\n",
    "\n",
    "# Convert input_data to torch tensor and ensure the correct shape\n",
    "input_data = torch.tensor(input_data, dtype=torch.float32)\n",
    "\n",
    "# Ensure input_data has shape (batch_size, num_channels, seq_length, height, width)\n",
    "# For example, if you have a single sequence of length 3 (hours), batch size 1:\n",
    "input_data = input_data.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "\n",
    "# Check if multiple GPUs are available and use DataParallel if so\n",
    "if torch.cuda.device_count() > 1:\n",
    "    logging.info(f\"Using {torch.cuda.device_count()} GPUs for model parallelism.\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "input_data = input_data.to(device)\n",
    "\n",
    "# Process data in batches using tqdm for progress tracking\n",
    "batch_size = 1\n",
    "num_batches = input_data.size(0) // batch_size\n",
    "\n",
    "logging.info(f\"Starting feature extraction for {num_batches} batches\")\n",
    "all_hidden_states = []\n",
    "\n",
    "for i in tqdm(range(num_batches), desc=\"Processing Batches\"):\n",
    "    batch_data = input_data[i*batch_size:(i+1)*batch_size]\n",
    "    print(batch_data.shape)\n",
    "    hidden_states = model(batch_data)\n",
    "    all_hidden_states.append(hidden_states)\n",
    "\n",
    "# Concatenate all hidden states\n",
    "all_hidden_states = torch.cat(all_hidden_states, dim=0)\n",
    "\n",
    "# Save hidden states for later use\n",
    "torch.save(all_hidden_states, 'hidden_states.ViT.pt')\n",
    "logging.info(\"Hidden states saved to hidden_states.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hidden_states.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Load hidden states\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhidden_states.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Convert hidden states to torch tensor\u001b[39;00m\n\u001b[1;32m     24\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(hidden_states\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# Reshape to (253, 1024)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hidden_states.npy'"
     ]
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2917, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0060, -0.0054, -0.0375,  ..., -0.0855, -0.0979,  0.0114],\n",
       "         [ 0.0054, -0.0120, -0.0622,  ..., -0.0865, -0.1101,  0.0175],\n",
       "         [ 0.0020, -0.0173, -0.0801,  ..., -0.0857, -0.1163,  0.0207],\n",
       "         ...,\n",
       "         [-0.0205,  0.0027, -0.0891,  ..., -0.0293, -0.0910,  0.0140],\n",
       "         [-0.0265,  0.0041, -0.0886,  ..., -0.0173, -0.0735,  0.0140],\n",
       "         [-0.0318,  0.0053, -0.0864,  ..., -0.0062, -0.0443,  0.0108]]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(all_hidden_states.shape)\n",
    "all_hidden_states"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
