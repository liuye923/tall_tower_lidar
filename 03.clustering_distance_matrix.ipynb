{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36938db1",
   "metadata": {},
   "source": [
    "Note: \n",
    "    \n",
    "Only run for winter, since we do clustering here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "898e7d46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce1e154d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc484368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rootdir = '/global/cfs/projectdirs/m1657/liuy351/TallTower/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17e94360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt_model = 'R18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f39ff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ts_full = pd.date_range('2001-01-01 00:00', end='2020-12-31 23:00', freq='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d91e00",
   "metadata": {},
   "source": [
    "## 1. Run a classifier to cluster weather systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f48e47",
   "metadata": {},
   "source": [
    "### 1.1 20 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "240368cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175320,) 52608\n"
     ]
    }
   ],
   "source": [
    "tag_20year = (ts_full.year>=2015)&(ts_full.year<=2020)\n",
    "print(tag_20year.shape, tag_20year.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "920b8076",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/projectdirs/m1657/liuy351/TallTower/ResNet_output/R18_output.anomaly.2001-2020.ERA5.mat\n",
      "(52608, 512)\n"
     ]
    }
   ],
   "source": [
    "infile = rootdir + 'ResNet_output/%s_output.anomaly.2001-2020.ERA5.mat' % opt_model\n",
    "print(infile)\n",
    "inds = sio.loadmat(infile)\n",
    "full_NCLtag = inds['ResNetoutput'][tag_20year==1]\n",
    "\n",
    "print(full_NCLtag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c496e7b6-76cf-4ceb-8cd4-a61ec6e4cbed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import dask.array as da\n",
    "# full_NCLtag = da.from_array(full_NCLtag, chunks=(128, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1bc2ce3-46f0-4065-a68d-1d587bc59bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52608, 52608)\n",
      "0:02:09.870056\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from multiprocessing import Pool\n",
    "import functools\n",
    "\n",
    "def compute_distances(data_chunk, full_data):\n",
    "    \"\"\"Compute distances between a chunk of data and the full dataset.\"\"\"\n",
    "    return cdist(data_chunk, full_data, metric='euclidean')\n",
    "\n",
    "def parallel_distance_matrix(data, num_splits):\n",
    "    \"\"\"Calculate the full distance matrix in parallel.\"\"\"\n",
    "    # Split data into chunks\n",
    "    chunks = np.array_split(data, num_splits)\n",
    "\n",
    "    # Create a pool of processes\n",
    "    with Pool() as pool:\n",
    "        # Partial function with fixed full_data\n",
    "        partial_compute_distances = functools.partial(compute_distances, full_data=data)\n",
    "        \n",
    "        # Map-reduce: map the function over the chunks and reduce the result\n",
    "        distance_chunks = pool.map(partial_compute_distances, chunks)\n",
    "\n",
    "    # Concatenate the results to form the full distance matrix\n",
    "    return np.vstack(distance_chunks)\n",
    "\n",
    "t1 = dt.datetime.now()\n",
    "# Example usage\n",
    "num_processors = 128  # Number of processors\n",
    "distance_matrix = parallel_distance_matrix(full_NCLtag, num_processors)\n",
    "t2 = dt.datetime.now()\n",
    "print(distance_matrix.shape)\n",
    "print((t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ea476e4-ba3a-421b-b14d-981f7e51b72b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "da = xr.DataArray(distance_matrix, dims=['x', 'y'])\n",
    "da.attrs['description'] = 'Calculate the distance matrix for reducing the computation of clustering'\n",
    "da.attrs['script'] = '/global/cfs/projectdirs/m1657/liuy351/TallTower/03.clustering_HDBSCAN.ipynb'\n",
    "da.to_netcdf(f'{rootdir}/ResNet_output/{opt_model}_distance_matrix.2015-2020.ERA5.nc')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myCompute",
   "language": "python",
   "name": "compute"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
