{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78e87c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import scipy.io as sio\n",
    "import datetime as dt\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.transform import rescale as skrescale\n",
    "from scipy import signal as ssignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a94b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vstring = int(sys.argv[1])\n",
    "rseed = int(42)\n",
    "#humidvar = sys.argv[3]\n",
    "import random\n",
    "random.seed(rseed)\n",
    "np.random.seed(rseed)\n",
    "torch.manual_seed(rseed)\n",
    "torch.cuda.manual_seed(rseed)\n",
    "torch.cuda.manual_seed_all(rseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a0553de",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_model = 'R18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7890a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24e87556",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCL(nn.Module):\n",
    "    \"\"\"\n",
    "    We opt for simplicity and adopt the commonly used ResNet (He et al., 2016) to obtain hi = f(x ̃i) = ResNet(x ̃i) where hi ∈ Rd is the output after the average pooling layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train, encoder, projection_dim, n_features):\n",
    "        super(SCL, self).__init__()\n",
    "        self.train = train\n",
    "        self.encoder = encoder\n",
    "        self.n_features = n_features\n",
    "\n",
    "        # increse input channel to 6\n",
    "        layer = self.encoder.conv1\n",
    "        new_nc = 6\n",
    "        new_layer = nn.Conv2d(in_channels=new_nc,\n",
    "                              out_channels=layer.out_channels,\n",
    "                              kernel_size=layer.kernel_size,\n",
    "                              stride=layer.stride,\n",
    "                              padding=layer.padding,\n",
    "                              bias=layer.bias)\n",
    "        # Extending the weights by copying from the old 3 to the new 3 channels\n",
    "        new_layer.weight.data[:, 0:3, :, :] = layer.weight.clone()\n",
    "        new_layer.weight.data[:, 3:6, :, :] = layer.weight.clone()\n",
    "        new_layer.weight = nn.Parameter(new_layer.weight)\n",
    "        self.encoder.conv1 = new_layer\n",
    "\n",
    "        # Replace the fc layer with an Identity function\n",
    "        self.encoder.fc = Identity()\n",
    "        # We use a MLP with one hidden layer to obtain z_i = g(h_i) = W(2)σ(W(1)h_i) where σ is a ReLU non-linearity.\n",
    "        # xc: This is the part that needs to be trained\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(self.n_features, self.n_features, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.n_features, projection_dim, bias=False),\n",
    "        )\n",
    "        # These are the parameters obtained from simCLR repo. I have also patched it to include 6 channels at the conv1\n",
    "        param_file = rootdir + 'model_lib/SCL_param.encoder.%s.6_channel.init.tar' % opt_model\n",
    "        self.encoder.load_state_dict(torch.load(param_file, map_location='cpu'))\n",
    "\n",
    "\n",
    "        # freeze the encoder so it is not re-trained\n",
    "        for param in self.encoder.parameters():\n",
    "            # param.requires_grad = False\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        # z_i = self.encoder(x_i.type(torch.FloatTensor).cuda()).type(torch.FloatTensor).cuda()\n",
    "        z_i = self.encoder(x_i.type(torch.FloatTensor)).type(torch.FloatTensor)\n",
    "        z_j = self.encoder(x_j.type(torch.FloatTensor)).type(torch.FloatTensor)\n",
    "\n",
    "        del x_i, x_j\n",
    "        return z_i, z_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2286bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_norm_data_by_var(my_var):\n",
    "\n",
    "    sfile_max = datadir + 'agg_40year/minmax/pt.max.%s.nc' % my_var\n",
    "    sfile_min = datadir + 'agg_40year/minmax/pt.min.%s.nc' % my_var\n",
    "\n",
    "    with xr.open_dataset(sfile_max) as inds:\n",
    "        ds_Vmax = inds[my_var].values\n",
    "\n",
    "    with xr.open_dataset(sfile_min) as inds:\n",
    "        ds_Vmin = inds[my_var].values\n",
    "        \n",
    "    print(ds_Vmax, ds_Vmin)\n",
    "\n",
    "    my_vmax = np.maximum(ds_Vmax, -1*ds_Vmin)\n",
    "    Vmax, Vmin = my_vmax, -1*my_vmax\n",
    "    \n",
    "    infile = datadir + 'ERA5.SCL.850mb_anomaly.%s.1981-2020.daymean.nc' % (my_var)\n",
    "    print('loading data from %s ...' % infile)\n",
    "    with xr.open_dataset(infile) as inds:\n",
    "        outdata = (inds[my_var].values[:,0,:,:]-Vmin)/(Vmax-Vmin)\n",
    "\n",
    "    return outdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "695ffd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean5kernel = np.ones((5,5))/25\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    '''\n",
    "    Since we need to mannually normalize the data, let's create datasets elsewhere, and just aggreagate them here.\n",
    "    Requires: T_full, H_full, W_full, U_full, V_full, Z_full\n",
    "    '''\n",
    "\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.sample_data = root_dir + 'ERA5.SCL.850mb_anomaly.W.1981-2020.daymean.nc'\n",
    "\n",
    "    def __len__(self):\n",
    "        with xr.open_dataset(self.sample_data) as inds:\n",
    "            nt = inds['W'].shape[0]\n",
    "        return int(nt) - 10\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # find a corresponding idx_pair, outside the 360-length window of idx\n",
    "        # idx_pair = xxxx\n",
    "\n",
    "        idx_pair = idx + 10\n",
    "\n",
    "\n",
    "        sample_raw = np.zeros((6,102,202))\n",
    "        sample_raw_pair = np.zeros((6,102,202))\n",
    "\n",
    "        for i,fullds in zip(np.arange(6), [H_full, T_full, W_full, U_full, V_full, Z_full]):\n",
    "            \n",
    "            # construct input for idx\n",
    "            # rescaling\n",
    "            data_step1 = skrescale(fullds[idx], (2.5, 2.5), anti_aliasing=True)\n",
    "            # mean using 5x5\n",
    "            data_step2 = ssignal.convolve2d(data_step1, mean5kernel, boundary='symm', mode='same')\n",
    "            sample_raw[i] = data_step2\n",
    "\n",
    "\n",
    "            # construct input for idx_pair\n",
    "            # rescaling\n",
    "            data_step1 = skrescale(fullds[idx_pair], (2.5, 2.5), anti_aliasing=True)\n",
    "            # mean using 5x5\n",
    "            data_step2 = ssignal.convolve2d(data_step1, mean5kernel, boundary='symm', mode='same')\n",
    "            sample_raw_pair[i] = data_step2\n",
    "\n",
    "        return sample_raw, sample_raw_pair, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4a9ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCLloss(my_x, my_y, my_temperature=0.5):\n",
    "    '''\n",
    "    my_x and my_y has a one-to-one pair. So there are in total N*N pairs. In these N*N, the diagonal pairs are positive,\n",
    "     and the rest are negative. So we want to maximum diagonal while suppressing the rest.\n",
    "    '''\n",
    "    ns = my_x.shape[0]\n",
    "    # use broadcasting to achieve pairwise cos. Note my_y.t() operation and dimension handling\n",
    "    cos_matrix = torch.nn.functional.cosine_similarity(my_x[:,:,None], my_y.t()[None,:,:])/my_temperature\n",
    "    similarity_matrix = torch.exp(cos_matrix)\n",
    "\n",
    "\n",
    "    loss = torch.tensor([0.0], requires_grad=True)\n",
    "    for i in np.arange(ns):\n",
    "        loss = loss -1*torch.log(similarity_matrix[i,i]/(torch.sum(similarity_matrix[i,:])-similarity_matrix[i,i]))\n",
    "        loss = loss -1*torch.log(similarity_matrix[i,i]/(torch.sum(similarity_matrix[:,i])-similarity_matrix[i,i]))\n",
    "\n",
    "    loss = loss/(2*ns)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd2f3fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '/global/cfs/projectdirs/m1657/liuy351/TallTower/From_XD/'\n",
    "\n",
    "datadir = '/global/cfs/projectdirs/m1657/liuy351/TallTower/From_XD/xdchen/anomaly/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "357b07f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. major parameters\n",
    "if opt_model=='R18':\n",
    "    batch_size = 128\n",
    "elif opt_model=='R15':\n",
    "    batch_size = 64\n",
    "    \n",
    "# 1. construct functions\n",
    "if opt_model=='R18':\n",
    "    encoder = torchvision.models.resnet18(weights=None)\n",
    "elif opt_model=='R50':\n",
    "    encoder = torchvision.models.resnet50(weights=None)\n",
    "\n",
    "n_features = encoder.fc.in_features  # get dimensions of fc layer\n",
    "\n",
    "# 2. construct two models, one with random parameters, one with pre-trained parameters\n",
    "projection_dim = 256\n",
    "SCL = SCL(True, encoder, projection_dim, n_features)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "SCL = SCL.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b56f49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.06845 -76.24047\n",
      "loading data from /global/cfs/projectdirs/m1657/liuy351/TallTower/From_XD/xdchen/anomaly/ERA5.SCL.850mb_anomaly.RH.1981-2020.daymean.nc ...\n",
      "20.074585 -34.17395\n",
      "loading data from /global/cfs/projectdirs/m1657/liuy351/TallTower/From_XD/xdchen/anomaly/ERA5.SCL.850mb_anomaly.T.1981-2020.daymean.nc ...\n",
      "26.455658 -35.592907\n",
      "loading data from /global/cfs/projectdirs/m1657/liuy351/TallTower/From_XD/xdchen/anomaly/ERA5.SCL.850mb_anomaly.U.1981-2020.daymean.nc ...\n",
      "44.648796 -33.113792\n",
      "loading data from /global/cfs/projectdirs/m1657/liuy351/TallTower/From_XD/xdchen/anomaly/ERA5.SCL.850mb_anomaly.V.1981-2020.daymean.nc ...\n",
      "7.01952 -5.8575945\n",
      "loading data from /global/cfs/projectdirs/m1657/liuy351/TallTower/From_XD/xdchen/anomaly/ERA5.SCL.850mb_anomaly.W.1981-2020.daymean.nc ...\n",
      "3010.4414 -4328.3145\n",
      "loading data from /global/cfs/projectdirs/m1657/liuy351/TallTower/From_XD/xdchen/anomaly/ERA5.SCL.850mb_anomaly.Z.1981-2020.daymean.nc ...\n",
      "(14610, 41, 81)\n"
     ]
    }
   ],
   "source": [
    "# 3. load data\n",
    "\n",
    "H_full = collect_norm_data_by_var('RH')\n",
    "T_full = collect_norm_data_by_var('T')\n",
    "U_full = collect_norm_data_by_var('U')\n",
    "V_full = collect_norm_data_by_var('V')\n",
    "W_full = collect_norm_data_by_var('W')\n",
    "Z_full = collect_norm_data_by_var('Z')\n",
    "\n",
    "print(Z_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2acb773",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(root_dir=datadir)\n",
    "\n",
    "# turn off shuffle, so data is processed in the time order\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f69af58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93a6fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NT_XentLoss(torch.nn.Module):\n",
    "    def __init__(self, batch_size, temperature, device):\n",
    "        super(NT_XentLoss, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.device = device\n",
    "        self.mask = self._get_mask(batch_size)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    def _get_mask(self, batch_size):\n",
    "        N = 2 * batch_size\n",
    "        mask = torch.ones((N, N), dtype=bool)\n",
    "        mask = mask.fill_diagonal_(0)\n",
    "        for i in range(batch_size):\n",
    "            mask[i, batch_size + i] = 0\n",
    "            mask[batch_size + i, i] = 0\n",
    "        return mask\n",
    "\n",
    "    def forward(self, zis, zjs):\n",
    "        N = 2 * self.batch_size\n",
    "        zis = F.normalize(zis, dim=1)\n",
    "        zjs = F.normalize(zjs, dim=1)\n",
    "        representations = torch.cat([zis, zjs], dim=0)\n",
    "\n",
    "        similarity_matrix = torch.matmul(representations, representations.T)\n",
    "        similarity_matrix = similarity_matrix / self.temperature\n",
    "\n",
    "        positives = torch.cat([torch.diag(similarity_matrix, self.batch_size),\n",
    "                               torch.diag(similarity_matrix, -self.batch_size)], dim=0)\n",
    "        negatives = similarity_matrix[self.mask].view(N, -1)\n",
    "\n",
    "        labels = torch.zeros(N).to(self.device).long()\n",
    "        logits = torch.cat([positives.unsqueeze(1), negatives], dim=1)\n",
    "\n",
    "        loss = self.criterion(logits, labels)\n",
    "        loss = loss / N\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1da0b748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 10:25:06.484296\n",
      "step: 1\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [1/10], Loss: 5.5661\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "0 128\n",
      "step: 2\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [2/10], Loss: 5.5783\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "128 256\n",
      "step: 3\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [3/10], Loss: 5.5362\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "256 384\n",
      "step: 4\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [4/10], Loss: 5.6315\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "384 512\n",
      "step: 5\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [5/10], Loss: 5.5928\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "512 640\n",
      "step: 6\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [6/10], Loss: 5.5828\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "640 768\n",
      "step: 7\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [7/10], Loss: 5.5788\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "768 896\n",
      "step: 8\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [8/10], Loss: 5.5422\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "896 1024\n",
      "step: 9\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [9/10], Loss: 5.5791\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "1024 1152\n",
      "step: 10\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [10/10], Loss: 5.5740\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "1152 1280\n",
      "step: 11\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [11/10], Loss: 5.5462\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "1280 1408\n",
      "step: 12\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [12/10], Loss: 5.5334\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "1408 1536\n",
      "step: 13\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [13/10], Loss: 5.5673\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "1536 1664\n",
      "step: 14\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [14/10], Loss: 5.5434\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "1664 1792\n",
      "step: 15\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [15/10], Loss: 5.5735\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "1792 1920\n",
      "step: 16\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [16/10], Loss: 5.5450\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "1920 2048\n",
      "step: 17\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [17/10], Loss: 5.5464\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "2048 2176\n",
      "step: 18\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [18/10], Loss: 5.5857\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "2176 2304\n",
      "step: 19\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [19/10], Loss: 5.5522\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "2304 2432\n",
      "step: 20\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [20/10], Loss: 5.5088\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "2432 2560\n",
      "step: 21\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [21/10], Loss: 5.5670\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "2560 2688\n",
      "step: 22\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [22/10], Loss: 5.5326\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "2688 2816\n",
      "step: 23\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [23/10], Loss: 5.5147\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "2816 2944\n",
      "step: 24\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [24/10], Loss: 5.5332\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "2944 3072\n",
      "step: 25\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [25/10], Loss: 5.5627\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "3072 3200\n",
      "step: 26\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [26/10], Loss: 5.5389\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "3200 3328\n",
      "step: 27\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [27/10], Loss: 5.5321\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "3328 3456\n",
      "step: 28\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [28/10], Loss: 5.5178\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "3456 3584\n",
      "step: 29\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [29/10], Loss: 5.5491\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "3584 3712\n",
      "step: 30\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [30/10], Loss: 5.5514\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "3712 3840\n",
      "step: 31\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [31/10], Loss: 5.5299\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "3840 3968\n",
      "step: 32\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [32/10], Loss: 5.5383\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "3968 4096\n",
      "step: 33\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [33/10], Loss: 5.5458\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "4096 4224\n",
      "step: 34\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [34/10], Loss: 5.5246\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "4224 4352\n",
      "step: 35\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [35/10], Loss: 5.5146\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "4352 4480\n",
      "step: 36\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [36/10], Loss: 5.5388\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "4480 4608\n",
      "step: 37\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [37/10], Loss: 5.5454\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "4608 4736\n",
      "step: 38\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [38/10], Loss: 5.5535\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "4736 4864\n",
      "step: 39\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [39/10], Loss: 5.5459\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "4864 4992\n",
      "step: 40\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [40/10], Loss: 5.5225\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "4992 5120\n",
      "step: 41\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [41/10], Loss: 5.5431\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "5120 5248\n",
      "step: 42\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [42/10], Loss: 5.5415\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "5248 5376\n",
      "step: 43\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [43/10], Loss: 5.5267\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "5376 5504\n",
      "step: 44\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [44/10], Loss: 5.5420\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "5504 5632\n",
      "step: 45\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [45/10], Loss: 5.5398\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "5632 5760\n",
      "step: 46\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [46/10], Loss: 5.5484\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "5760 5888\n",
      "step: 47\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [47/10], Loss: 5.5367\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "5888 6016\n",
      "step: 48\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [48/10], Loss: 5.4963\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "6016 6144\n",
      "step: 49\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [49/10], Loss: 5.5467\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "6144 6272\n",
      "step: 50\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [50/10], Loss: 5.5145\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "6272 6400\n",
      "step: 51\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [51/10], Loss: 5.5223\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "6400 6528\n",
      "step: 52\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [52/10], Loss: 5.5400\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "6528 6656\n",
      "step: 53\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [53/10], Loss: 5.5204\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "6656 6784\n",
      "step: 54\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [54/10], Loss: 5.5350\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "6784 6912\n",
      "step: 55\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [55/10], Loss: 5.5284\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "6912 7040\n",
      "step: 56\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [56/10], Loss: 5.5589\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "7040 7168\n",
      "step: 57\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [57/10], Loss: 5.5500\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "7168 7296\n",
      "step: 58\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [58/10], Loss: 5.5453\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "7296 7424\n",
      "step: 59\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [59/10], Loss: 5.5529\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "7424 7552\n",
      "step: 60\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [60/10], Loss: 5.5198\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "7552 7680\n",
      "step: 61\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [61/10], Loss: 5.4866\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "7680 7808\n",
      "step: 62\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [62/10], Loss: 5.5269\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "7808 7936\n",
      "step: 63\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [63/10], Loss: 5.5378\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "7936 8064\n",
      "step: 64\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [64/10], Loss: 5.5670\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "8064 8192\n",
      "step: 65\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [65/10], Loss: 5.5539\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "8192 8320\n",
      "step: 66\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [66/10], Loss: 5.5634\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "8320 8448\n",
      "step: 67\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [67/10], Loss: 5.5523\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "8448 8576\n",
      "step: 68\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [68/10], Loss: 5.5990\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "8576 8704\n",
      "step: 69\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [69/10], Loss: 5.5555\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "8704 8832\n",
      "step: 70\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [70/10], Loss: 5.5173\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "8832 8960\n",
      "step: 71\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [71/10], Loss: 5.5171\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "8960 9088\n",
      "step: 72\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [72/10], Loss: 5.5490\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "9088 9216\n",
      "step: 73\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [73/10], Loss: 5.5203\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "9216 9344\n",
      "step: 74\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [74/10], Loss: 5.4899\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "9344 9472\n",
      "step: 75\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [75/10], Loss: 5.5448\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "9472 9600\n",
      "step: 76\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [76/10], Loss: 5.5283\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "9600 9728\n",
      "step: 77\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [77/10], Loss: 5.4753\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "9728 9856\n",
      "step: 78\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [78/10], Loss: 5.5272\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "9856 9984\n",
      "step: 79\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [79/10], Loss: 5.5124\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "9984 10112\n",
      "step: 80\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [80/10], Loss: 5.5122\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "10112 10240\n",
      "step: 81\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [81/10], Loss: 5.5407\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "10240 10368\n",
      "step: 82\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [82/10], Loss: 5.5348\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "10368 10496\n",
      "step: 83\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [83/10], Loss: 5.5401\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "10496 10624\n",
      "step: 84\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [84/10], Loss: 5.5739\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "10624 10752\n",
      "step: 85\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [85/10], Loss: 5.5206\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "10752 10880\n",
      "step: 86\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [86/10], Loss: 5.5772\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "10880 11008\n",
      "step: 87\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [87/10], Loss: 5.4984\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "11008 11136\n",
      "step: 88\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [88/10], Loss: 5.4698\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "11136 11264\n",
      "step: 89\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [89/10], Loss: 5.5797\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "11264 11392\n",
      "step: 90\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [90/10], Loss: 5.4591\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "11392 11520\n",
      "step: 91\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [91/10], Loss: 5.4503\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "11520 11648\n",
      "step: 92\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [92/10], Loss: 5.5915\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "11648 11776\n",
      "step: 93\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [93/10], Loss: 5.4908\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "11776 11904\n",
      "step: 94\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [94/10], Loss: 5.5276\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "11904 12032\n",
      "step: 95\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [95/10], Loss: 5.5110\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "12032 12160\n",
      "step: 96\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [96/10], Loss: 5.5069\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "12160 12288\n",
      "step: 97\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [97/10], Loss: 5.4541\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "12288 12416\n",
      "step: 98\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [98/10], Loss: 5.5552\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "12416 12544\n",
      "step: 99\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [99/10], Loss: 5.5898\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "12544 12672\n",
      "step: 100\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [100/10], Loss: 5.4904\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "12672 12800\n",
      "step: 101\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [101/10], Loss: 5.5497\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "12800 12928\n",
      "step: 102\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [102/10], Loss: 5.4930\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "12928 13056\n",
      "step: 103\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [103/10], Loss: 5.5771\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "13056 13184\n",
      "step: 104\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [104/10], Loss: 5.4659\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "13184 13312\n",
      "step: 105\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [105/10], Loss: 5.4912\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "13312 13440\n",
      "step: 106\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [106/10], Loss: 5.5719\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "13440 13568\n",
      "step: 107\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [107/10], Loss: 5.4716\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "13568 13696\n",
      "step: 108\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [108/10], Loss: 5.5117\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "13696 13824\n",
      "step: 109\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [109/10], Loss: 5.5656\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "13824 13952\n",
      "step: 110\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [110/10], Loss: 5.6079\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "13952 14080\n",
      "step: 111\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [111/10], Loss: 5.4984\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "14080 14208\n",
      "step: 112\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [112/10], Loss: 5.5526\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "14208 14336\n",
      "step: 113\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [113/10], Loss: 5.5095\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "14336 14464\n",
      "step: 114\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128, 512])\n",
      "Step [114/10], Loss: 5.5263\n",
      "2\n",
      "torch.Size([128, 512])\n",
      "14464 14592\n",
      "step: 115\n",
      "torch.Size([8, 512])\n",
      "torch.Size([8, 512])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [256, 256] at index 0 does not match the shape of the indexed tensor [16, 16] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(testout[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(testout[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 17\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestout\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestout\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[36], line 33\u001b[0m, in \u001b[0;36mNT_XentLoss.forward\u001b[0;34m(self, zis, zjs)\u001b[0m\n\u001b[1;32m     29\u001b[0m similarity_matrix \u001b[38;5;241m=\u001b[39m similarity_matrix \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemperature\n\u001b[1;32m     31\u001b[0m positives \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([torch\u001b[38;5;241m.\u001b[39mdiag(similarity_matrix, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size),\n\u001b[1;32m     32\u001b[0m                        torch\u001b[38;5;241m.\u001b[39mdiag(similarity_matrix, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m negatives \u001b[38;5;241m=\u001b[39m \u001b[43msimilarity_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mview(N, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     35\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(N)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     36\u001b[0m logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([positives\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), negatives], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [256, 256] at index 0 does not match the shape of the indexed tensor [16, 16] at index 0"
     ]
    }
   ],
   "source": [
    "outdata = np.zeros((2, H_full.shape[0], n_features))\n",
    "outindex = np.zeros(H_full.shape[0])\n",
    "\n",
    "sindex = -1*batch_size\n",
    "eindex = 0\n",
    "\n",
    "criterion = NT_XentLoss(batch_size=batch_size, temperature=0.5, device='cpu')\n",
    "optimizer = optim.Adam(SCL.parameters(), lr=0.001)\n",
    "\n",
    "print(dt.datetime.now())\n",
    "for step, data in enumerate(train_dataloader):\n",
    "    print(f'step: {step+1}')\n",
    "    optimizer.zero_grad()\n",
    "    testout = SCL(data[0].to(device), data[1].to(device))\n",
    "    print(testout[0].shape)\n",
    "    print(testout[1].shape)\n",
    "    loss = criterion(testout[0], testout[1])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Step [{step+1}/10], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    print(len(testout))\n",
    "    print(testout[0].shape)\n",
    "\n",
    "\n",
    "    sindex = eindex\n",
    "    eindex += testout[0].shape[0]\n",
    "\n",
    "    outdata[0,sindex:eindex, :] = testout[0].detach().cpu().numpy()\n",
    "    outindex[sindex:eindex] = data[2]\n",
    "\n",
    "    print(sindex, eindex)\n",
    "\n",
    "print(dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7cc2155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to /global/cfs/projectdirs/m1657/liuy351/TallTower/From_XD/ResNet_output/RH_input/R18_output.anomaly.daymean.1981-2020.ERA5.mat ...\n"
     ]
    }
   ],
   "source": [
    "outfile = rootdir + 'ResNet_output/RH_input/%s_output.anomaly.daymean.1981-2020.ERA5.mat' % opt_model\n",
    "print('writing to %s ...' % outfile)\n",
    "description = 'Just the simCLR encoder output. So in 512 dimension. Use %s model' % opt_model\n",
    "script = '/global/cfs/projectdirs/m1657/liuy351/TallTower/From_XD/step02.ResNet_encoder_production_run.ipynb'\n",
    "sio.savemat(outfile, {'ResNetoutput':outdata, 'tindex':outindex, 'description':description, 'script':script})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d9000b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9530\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9400\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9470\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9420\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9495\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9580\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9582\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9443\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9457\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9439\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9417\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9472\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9457\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9472\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9481\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9476\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9400\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9451\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9387\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9478\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9372\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9435\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9567\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9470\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9413\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9481\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9383\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9538\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9491\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9426\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9328\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9465\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9354\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9325\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9333\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9722\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9574\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9469\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9650\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9402\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9605\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9503\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9162\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9326\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9134\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9368\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9597\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9991\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.8661\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9460\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9328\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9500\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9417\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9460\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9484\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9461\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9460\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9465\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9466\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9470\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9457\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9463\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9452\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9461\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9453\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9457\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9463\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9445\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9462\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9457\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9459\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9462\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9455\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9451\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9450\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9470\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9445\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9464\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9455\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9458\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9443\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9470\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9467\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9453\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9460\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9458\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9461\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9474\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9464\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9454\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9458\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9461\n",
      "torch.Size([4, 1000])\n",
      "step [1/3], Loss: 1.9461\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 105\u001b[0m\n\u001b[1;32m    103\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    104\u001b[0m z1 \u001b[38;5;241m=\u001b[39m model(x1)\n\u001b[0;32m--> 105\u001b[0m z2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m(z1\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    107\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(z1, z2)\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 52\u001b[0m, in \u001b[0;36mContrastiveModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 52\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m z\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 43\u001b[0m, in \u001b[0;36mViTEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/vit_pytorch/vit.py:122\u001b[0m, in \u001b[0;36mViT.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    119\u001b[0m x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embedding[:, :(n \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m    120\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m--> 122\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmean(dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    126\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_latent(x)\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/vit_pytorch/vit.py:78\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attn, ff \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 78\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m x\n\u001b[1;32m     79\u001b[0m         x \u001b[38;5;241m=\u001b[39m ff(x) \u001b[38;5;241m+\u001b[39m x\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/vit_pytorch/vit.py:58\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m t: rearrange(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb n (h d) -> b h n d\u001b[39m\u001b[38;5;124m'\u001b[39m, h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads), qkv)\n\u001b[1;32m     56\u001b[0m dots \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(q, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\n\u001b[0;32m---> 58\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdots\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attn)\n\u001b[1;32m     61\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(attn, v)\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/nn/modules/activation.py:1545\u001b[0m, in \u001b[0;36mSoftmax.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/compute/lib/python3.11/site-packages/torch/nn/functional.py:1885\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1883\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1887\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from vit_pytorch import ViT\n",
    "\n",
    "# 定义时间序列数据集\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, interval=10):\n",
    "        self.data = data\n",
    "        self.interval = interval\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] - self.interval\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x1 = self.data[idx]\n",
    "        x2 = self.data[idx + self.interval]\n",
    "        return x1, x2\n",
    "\n",
    "# 假设数据已经加载为numpy数组\n",
    "data = torch.randn(1440, 3, 224, 224)  # 示例数据，假设是RGB图像\n",
    "dataset = TimeSeriesDataset(data, interval=10)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# 定义ViT编码器（假设已包含MLP投影）\n",
    "class ViTEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ViTEncoder, self).__init__()\n",
    "        self.vit = ViT(\n",
    "            image_size = 224,\n",
    "            patch_size = 16,\n",
    "            num_classes = 1000,  # 这里的 num_classes 可以忽略，因为我们不使用它\n",
    "            dim = 512,\n",
    "            depth = 6,\n",
    "            heads = 8,\n",
    "            mlp_dim = 512,\n",
    "            dropout = 0.1,\n",
    "            emb_dropout = 0.1\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.vit(x)\n",
    "\n",
    "# 定义对比学习模型\n",
    "class ContrastiveModel(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super(ContrastiveModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return z\n",
    "\n",
    "# 定义NT_Xent损失函数\n",
    "class NT_XentLoss(nn.Module):\n",
    "    def __init__(self, batch_size, temperature, device):\n",
    "        super(NT_XentLoss, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.device = device\n",
    "        self.mask = self._get_mask(batch_size)\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    def _get_mask(self, batch_size):\n",
    "        N = 2 * batch_size\n",
    "        mask = torch.ones((N, N), dtype=bool)\n",
    "        mask = mask.fill_diagonal_(0)\n",
    "        for i in range(batch_size):\n",
    "            mask[i, batch_size + i] = 0\n",
    "            mask[batch_size + i, i] = 0\n",
    "        return mask\n",
    "\n",
    "    def forward(self, zis, zjs):\n",
    "        N = 2 * self.batch_size\n",
    "        zis = F.normalize(zis, dim=1)\n",
    "        zjs = F.normalize(zjs, dim=1)\n",
    "        representations = torch.cat([zis, zjs], dim=0)\n",
    "\n",
    "        similarity_matrix = torch.matmul(representations, representations.T)\n",
    "        similarity_matrix = similarity_matrix / self.temperature\n",
    "\n",
    "        positives = torch.cat([torch.diag(similarity_matrix, self.batch_size),\n",
    "                               torch.diag(similarity_matrix, -self.batch_size)], dim=0)\n",
    "        negatives = similarity_matrix[self.mask].view(N, -1)\n",
    "\n",
    "        labels = torch.zeros(N).to(self.device).long()\n",
    "        logits = torch.cat([positives.unsqueeze(1), negatives], dim=1)\n",
    "\n",
    "        loss = self.criterion(logits, labels)\n",
    "        loss = loss / N\n",
    "        return loss\n",
    "\n",
    "# 实例化模型\n",
    "encoder = ViTEncoder()\n",
    "model = ContrastiveModel(encoder)\n",
    "criterion = NT_XentLoss(batch_size=4, temperature=0.5, device='cpu')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(3):  # 训练10个周期\n",
    "    for x1, x2 in dataloader:  # 遍历每个批次\n",
    "        optimizer.zero_grad()\n",
    "        z1 = model(x1)\n",
    "        z2 = model(x2)\n",
    "        print(z1.shape)\n",
    "        loss = criterion(z1, z2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"step [{epoch+1}/3], Loss: {loss.item():.4f}\")\n",
    "    print(f\"Epoch [{epoch+1}/3], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Training finished.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
